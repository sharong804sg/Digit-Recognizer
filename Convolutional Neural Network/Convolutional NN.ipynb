{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451c584d",
   "metadata": {},
   "source": [
    "Environment: pytorch\n",
    "\n",
    "# <font color='purple'>Convolutional Neural Network\n",
    "In this notebook, we build and tune a convolutional neural network to classify the MNIST samples as one of 10 digits: 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21298d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ac8968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sharo\\\\Documents\\\\Postgrad\\\\My Data Science Portfolio\\\\Classification - MNIST'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\sharo\\Documents\\Postgrad\\My Data Science Portfolio\\Classification - MNIST\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2061814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ffac0",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Import Training Data & Reserve Mock-Test Set\n",
    "Mock test dataset will not be used for hyperparameter tuning, but instead reserved for final evaluation of tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85958286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_df(fp, label_colname, my_seed=None):\n",
    "    \"\"\"\n",
    "    Function to import raw data, carry out pre-processing, and split into training and test datasets.\n",
    "    Test data will be reserved for final evaluation of model performance (i.e. not for hyperparameter tuning)\n",
    "\n",
    "    :param fp: filepath\n",
    "    :param label_colname: name of column containing labels\n",
    "    :param my_seed: integer to be used to fix random state for train_test_split\n",
    "\n",
    "    :return: tuple of dataframes - training_df, test_df\n",
    "    \"\"\"\n",
    "\n",
    "    # import data\n",
    "    df = pd.read_csv(fp)\n",
    "\n",
    "    # Standard scaling of features #TODO: try with and without\n",
    "    scaler = StandardScaler()\n",
    "    df[df.drop(columns=label_colname).columns] = scaler.fit_transform(df[df.drop(columns=label_colname).columns])\n",
    "\n",
    "    # separate into training & test datasets.\n",
    "    # Stratification is used to ensure training and test sets have representative proportions of all classes\n",
    "    training_df, test_df = train_test_split(df, test_size=0.3, random_state=my_seed, stratify=df[label_colname])\n",
    "\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea610b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the unfiltered dataset as full set of pixels is required for CNN\n",
    "training_df, mytest_df = get_train_test_df(\"train.csv\", label_colname='label', my_seed = my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5d301",
   "metadata": {},
   "source": [
    "**Plot a few digits**   \n",
    "Note that, unlike code for feed-forward neural network, definition of MyDataset below reassembles the flattened array of pixels for each image into a 28x28 px image to facilitate convolution later on.\n",
    "\n",
    "We plot a few digits to check that this reassembly was done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87795353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): # inherits properties of pytorch Dataset class\n",
    "    def __init__(self, dataframe, label_colname=None, blind_test=False):\n",
    "        \"\"\"\n",
    "            Class initialisation\n",
    "            :param dataframe: pandas dataframe including features and labels\n",
    "            :param label_colname: name of column containing labels\n",
    "            :param blind_test: Boolean. True means dataframe does not include labels (i.e. test set)\n",
    "            \"\"\"\n",
    "        self.blind_test = blind_test\n",
    "\n",
    "        if blind_test:  # for blind test (i.e. no label, self.labels does not exist)\n",
    "            self.features = dataframe.to_numpy()\n",
    "        else:\n",
    "            self.features = dataframe.drop(columns=[label_colname]).to_numpy()\n",
    "            self.labels = dataframe[label_colname].to_numpy()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return: length of dataset\n",
    "        \"\"\"\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetches features and label(s) at requested index\n",
    "        :param idx: requested index\n",
    "        :return: tuple of numpy arrays - batch_features, batch_labels. For blind test, return only batch_features\n",
    "        \"\"\"\n",
    "        batch_features = self.features[idx, :]\n",
    "        batch_images = np.zeros((1, 28, 28))  # initialise array for next datapoint. A 28x28px image\n",
    "        for i in range(28):  # rows\n",
    "            for j in range(28):  # columns\n",
    "                x = i * 28 + j  # pixel (i,j) from the original img is located in column x of flattened img\n",
    "                batch_images[0, i, j] = batch_features[x]\n",
    "\n",
    "        if self.blind_test:\n",
    "            return batch_images\n",
    "        else:\n",
    "            batch_labels = self.labels[idx]\n",
    "            return batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8414ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format training dataframe as pytorch dataloader\n",
    "check_dataset = MyDataset(training_df, 'label')\n",
    "check_dataloader = DataLoader(check_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# get first batch of images and their labels\n",
    "check_iter = iter(check_dataloader)\n",
    "images, labels = next(check_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b6361ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x250 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(15, 2.5), ncols=5)\n",
    "ax = ax.flatten()\n",
    "for i in range(len(images)):\n",
    "    ax[i].imshow(np.transpose(images[i], (1, 2, 0)))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(f\"Label: {labels[i].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aacfb5",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>Train Model\n",
    "**Tune Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831dfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(trial):\n",
    "    \"\"\"\n",
    "    Set parameters for neural network, optimisation algorithm etc.\n",
    "    :param trial: Optuna trial object\n",
    "    :return: dictionary of parameters:\n",
    "            - n_conv_layers: number of convolution layers in neural network\n",
    "            - out_ch_conv{i}: number of output channels in convolution layer i\n",
    "            - kernel_conv{i}_even: kernel width in convolution layer i - even option\n",
    "            - kernel_conv{i}_odd:                                      - odd option\n",
    "\n",
    "            - n_linear_layers: number of linear layers in neural network\n",
    "            - n_units_lin{i}: number of units in linear layer i\n",
    "            - dropout_lin{i}: dropout probability for linear layer i\n",
    "\n",
    "            - lr: learning rate\n",
    "            - batch_size: batch size\n",
    "            - n_epochs = number of epochs (i.e. number of passes through training data during optimisation)\n",
    "    \"\"\"\n",
    "    trial.suggest_int(\"n_conv_layers\", 1, 2)\n",
    "\n",
    "    for i in range(trial.params['n_conv_layers']):\n",
    "        trial.suggest_int(f'out_ch_conv{i}', 1, 20)\n",
    "        trial.suggest_categorical(f'kernel_conv{i}_even', [2, 4, 6])\n",
    "        trial.suggest_categorical(f'kernel_conv{i}_odd', [3, 5, 7])\n",
    "\n",
    "    trial.suggest_int(\"n_linear_layers\", 1, 3)\n",
    "\n",
    "    for i in range(trial.params['n_linear_layers']):\n",
    "        trial.suggest_int(f'n_units_lin{i}', 1, 200)\n",
    "        trial.suggest_float(f\"dropout_lin{i}\", 0.1, 0.9)\n",
    "\n",
    "    trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # TODO: try optimising these as well\n",
    "    trial.suggest_int(\"batch_size\", 10, 10)\n",
    "    trial.suggest_int(\"n_epochs\", 5, 5)\n",
    "    trial.suggest_categorical(\"optimizer\",[\"SGD\"])\n",
    "\n",
    "    my_params = trial.params\n",
    "\n",
    "    return my_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c45848aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(my_params):\n",
    "    \"\"\"Defines convolutional neural network based on set parameters\n",
    "    :param my_params: dictionary of parameters (see set_parameters() for full list)\n",
    "    \"\"\"\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    # Define Convolution Layers\n",
    "    in_ch = 1  # number of input channels = no. of channels in feature matrix = 1\n",
    "    img_width = 28 # number of px along length & width of feature matrix\n",
    "    for i in range(my_params['n_conv_layers']):\n",
    "        # convolution layer\n",
    "        out_ch = my_params[f'out_ch_conv{i}']  # number of output channels for this layer\n",
    "        # for even image width use odd kernel width so that resulting img width is divisible by 2 during pooling\n",
    "        if (img_width % 2) == 0:\n",
    "            kernel_size = my_params[f'kernel_conv{i}_odd']\n",
    "        else:\n",
    "            kernel_size = my_params[f'kernel_conv{i}_even']\n",
    "        layers.append(nn.Conv2d(in_ch, out_ch, kernel_size))\n",
    "\n",
    "        layers.append(nn.ReLU())  # activation function\n",
    "        layers.append(nn.MaxPool2d(2, 2))  # pooling layer\n",
    "\n",
    "        in_ch = out_ch  # no. of input channels for next layer = no. of output channels from this layer\n",
    "        img_width = int((img_width-(kernel_size-1))/2)\n",
    "\n",
    "    layers.append(nn.Flatten(start_dim=1))  # flatten all dimensions except batch\n",
    "\n",
    "    # Define Linear Layers\n",
    "    in_features = in_ch * img_width * img_width\n",
    "    for i in range(my_params['n_linear_layers']):\n",
    "        # linear layer\n",
    "        out_features = my_params[f'n_units_lin{i}']\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "\n",
    "        layers.append(nn.ReLU())  # activation function\n",
    "\n",
    "        #drop-out regularisation\n",
    "        p = my_params[f\"dropout_lin{i}\"]\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features  # no. of inputs for next layer = no. of outputs of this layer\n",
    "\n",
    "    layers.append(nn.Linear(in_features, 10))  # output layer\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd8526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_dataloader(training_df, my_batchsize, label_colname, my_seed = None):\n",
    "    \"\"\"\n",
    "    Function to split training data into training and validation subsets and format as dataloaders\n",
    "    Model performance on validation set will be used for hyperparameter tuning.\n",
    "\n",
    "    :param training_df: dataframe with full set of training data\n",
    "    :param my_batchsize: batch size for pytorch DataLoader\n",
    "    :param label_colname: name of column containing labels\n",
    "    :param my_seed: optional integer to fix train test split random state\n",
    "\n",
    "    :return: tuple of pytorch DataLoaders - train_dataloader, val_dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    # separate into training & validation datasets\n",
    "    train_data, val_data = train_test_split(training_df, test_size = 0.2, random_state = my_seed, stratify=training_df[label_colname])\n",
    "\n",
    "    #format as pytorch dataloader\n",
    "    train, val = MyDataset(train_data, label_colname), MyDataset(val_data, label_colname)\n",
    "    train_dataloader = DataLoader(train, batch_size=my_batchsize, shuffle=True)\n",
    "    val_dataloader = DataLoader(val, batch_size=my_batchsize)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78304455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_correct(predictions, y):\n",
    "    \"\"\"\n",
    "    Counts number of correct predictions in a batch\n",
    "\n",
    "    :param predictions: 1D tensor with predictions\n",
    "    :param y: 1D tensor with true classes\n",
    "\n",
    "    :return: number of correct predictions (pred==y)\n",
    "    \"\"\"\n",
    "    predictions = predictions.numpy()\n",
    "    y = y.numpy()\n",
    "\n",
    "    n_correct = (predictions == y).sum()\n",
    "\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32e8806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective for Optuna to optimise\n",
    "    :param trial: Optuna trial object\n",
    "    :return: accuracy - fraction of correctly labelled validation points. This is what Optuna seeks to maximise\n",
    "    \"\"\"\n",
    "\n",
    "    #set parameters\n",
    "    my_params = set_parameters(trial)\n",
    "\n",
    "    # Instantiate model\n",
    "    model = define_model(my_params)\n",
    "\n",
    "    # Instantiate optimizer\n",
    "    optimizer_name = my_params['optimizer']\n",
    "    lr = my_params['lr']\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # get data\n",
    "    train_dataloader, val_dataloader = get_train_val_dataloader(training_df,\n",
    "                                                                my_batchsize=my_params['batch_size'],\n",
    "                                                                label_colname='label')\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(my_params['n_epochs']):\n",
    "\n",
    "        #train\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # X and y are tensors. X.size() = (batch_size,n_features), y.size()=(batch_size,)\n",
    "            # set datatype for compatibility with nn.\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "\n",
    "            # calculate model output and resulting loss\n",
    "            model_output = model(X)  # tensor. size=(batch_size x n_classes)\n",
    "            loss_fn = nn.CrossEntropyLoss() # instantiate loss function\n",
    "            loss = loss_fn(model_output, y)\n",
    "\n",
    "            # Backpropagation to update model weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validate. We do this at each epoch to facilitate pruning:\n",
    "        # i.e. early termination of trials which are clearly not going to be optimum\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch, (X, y) in enumerate(val_dataloader):\n",
    "                X = X.float()\n",
    "                y = y.long()\n",
    "\n",
    "                # calculate model output and total number of correct predictions for this batch\n",
    "                model_output = model(X)\n",
    "                pred = torch.argmax(model_output, dim=1)  # prediction = class with highest output value\n",
    "                correct += count_correct(pred, y)\n",
    "\n",
    "        accuracy = correct / len(val_dataloader.dataset)\n",
    "\n",
    "        # report accuracy to allow Optuna to decide whether to prune this trial\n",
    "        trial.report(accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy  # return final validation accuracy after all epochs (unless pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a4f285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 12:58:57,743]\u001b[0m A new study created in memory with name: no-name-5a5bdf9d-81df-4bd5-bce4-dbca3438b459\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:00:49,585]\u001b[0m Trial 0 finished with value: 0.4437074829931973 and parameters: {'n_conv_layers': 1, 'out_ch_conv0': 18, 'kernel_conv0_even': 2, 'kernel_conv0_odd': 5, 'n_linear_layers': 3, 'n_units_lin0': 82, 'dropout_lin0': 0.6551025614650803, 'n_units_lin1': 73, 'dropout_lin1': 0.8768654008802214, 'n_units_lin2': 89, 'dropout_lin2': 0.4101680331994084, 'lr': 0.0018316249889512787, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4437074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:02:24,311]\u001b[0m Trial 1 finished with value: 0.9217687074829932 and parameters: {'n_conv_layers': 1, 'out_ch_conv0': 3, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'n_linear_layers': 3, 'n_units_lin0': 182, 'dropout_lin0': 0.17312337412644663, 'n_units_lin1': 127, 'dropout_lin1': 0.6682209863018902, 'n_units_lin2': 49, 'dropout_lin2': 0.18205458768048421, 'lr': 0.0024488162224670855, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.9217687074829932.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:04:00,631]\u001b[0m Trial 2 finished with value: 0.9744897959183674 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 1, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 162, 'dropout_lin0': 0.5631204272169147, 'lr': 0.02194408170309152, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9744897959183674.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:05:30,610]\u001b[0m Trial 3 finished with value: 0.9554421768707483 and parameters: {'n_conv_layers': 1, 'out_ch_conv0': 7, 'kernel_conv0_even': 2, 'kernel_conv0_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 94, 'dropout_lin0': 0.8854683264635196, 'lr': 0.02118502617030419, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9744897959183674.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:07:17,662]\u001b[0m Trial 4 finished with value: 0.8472789115646259 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 15, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 3, 'out_ch_conv1': 12, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 7, 'n_linear_layers': 1, 'n_units_lin0': 144, 'dropout_lin0': 0.264969341338119, 'lr': 0.0003019363652587547, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9744897959183674.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:07:39,823]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:07:58,148]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:08:19,805]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:09:20,780]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:10:23,119]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:10:43,503]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:11:01,489]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:12:37,268]\u001b[0m Trial 12 finished with value: 0.9683673469387755 and parameters: {'n_conv_layers': 1, 'out_ch_conv0': 13, 'kernel_conv0_even': 2, 'kernel_conv0_odd': 7, 'n_linear_layers': 1, 'n_units_lin0': 45, 'dropout_lin0': 0.711859591161799, 'lr': 0.016658853606879846, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9744897959183674.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:14:13,611]\u001b[0m Trial 13 finished with value: 0.9664965986394558 and parameters: {'n_conv_layers': 1, 'out_ch_conv0': 13, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'n_linear_layers': 1, 'n_units_lin0': 33, 'dropout_lin0': 0.7211668443863593, 'lr': 0.009491944748183843, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.9744897959183674.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:14:33,730]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:16:21,748]\u001b[0m Trial 15 finished with value: 0.9795918367346939 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 13, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 53, 'dropout_lin0': 0.7154242717217065, 'lr': 0.010439061826513307, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 15 with value: 0.9795918367346939.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:16:42,240]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:18:26,597]\u001b[0m Trial 17 finished with value: 0.9843537414965986 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 10, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 16, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 63, 'dropout_lin0': 0.5295183218658674, 'lr': 0.026927663988271885, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:18:48,260]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:19:09,301]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:19:31,163]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:21:08,472]\u001b[0m Trial 21 finished with value: 0.9712585034013606 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 4, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 25, 'dropout_lin0': 0.510131155447382, 'lr': 0.018067742539350538, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:22:46,364]\u001b[0m Trial 22 finished with value: 0.9782312925170068 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 7, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 18, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 117, 'dropout_lin0': 0.5937002682947722, 'lr': 0.04433533218528084, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:24:26,700]\u001b[0m Trial 23 finished with value: 0.9772108843537415 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 7, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 17, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 129, 'dropout_lin0': 0.6571483273354721, 'lr': 0.04601735329077512, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:24:47,792]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:25:07,323]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:25:29,419]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:25:51,614]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:26:13,238]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:26:34,448]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:26:57,125]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:28:36,718]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:30:15,383]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:31:56,317]\u001b[0m Trial 33 finished with value: 0.9785714285714285 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 8, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 18, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 71, 'dropout_lin0': 0.5384464081024504, 'lr': 0.036889835694038274, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:33:44,089]\u001b[0m Trial 34 finished with value: 0.9818027210884354 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 10, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 19, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 70, 'dropout_lin0': 0.4977678440164699, 'lr': 0.027385725171761542, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:35:30,821]\u001b[0m Trial 35 finished with value: 0.9821428571428571 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 10, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 5, 'out_ch_conv1': 19, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 70, 'dropout_lin0': 0.3825528834296854, 'lr': 0.012799242628694876, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 13:35:52,734]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:36:15,582]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:38:02,765]\u001b[0m Trial 38 finished with value: 0.9811224489795919 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 12, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 53, 'dropout_lin0': 0.2274436791631837, 'lr': 0.025232466556732322, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:38:24,459]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:38:43,860]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:40:30,296]\u001b[0m Trial 41 finished with value: 0.9809523809523809 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 10, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 56, 'dropout_lin0': 0.3860780694557905, 'lr': 0.022974028878832393, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:42:20,508]\u001b[0m Trial 42 finished with value: 0.9821428571428571 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 10, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 19, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 61, 'dropout_lin0': 0.3759114835353559, 'lr': 0.023516800686989883, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:42:42,801]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:43:04,414]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:44:56,464]\u001b[0m Trial 45 finished with value: 0.9821428571428571 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 20, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 12, 'kernel_conv1_even': 6, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 77, 'dropout_lin0': 0.10524241718835126, 'lr': 0.015524749614804791, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:46:47,027]\u001b[0m Trial 46 finished with value: 0.9787414965986394 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 19, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 12, 'kernel_conv1_even': 6, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 75, 'dropout_lin0': 0.11392024630428588, 'lr': 0.06682225640901988, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:47:07,821]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:47:29,088]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:47:49,705]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:48:10,575]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:49:57,777]\u001b[0m Trial 51 finished with value: 0.9792517006802721 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 11, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 19, 'kernel_conv1_even': 2, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 47, 'dropout_lin0': 0.14711262656574559, 'lr': 0.01741281416456215, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:50:19,072]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:52:11,513]\u001b[0m Trial 53 finished with value: 0.9802721088435374 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 20, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 15, 'kernel_conv1_even': 6, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 61, 'dropout_lin0': 0.2949196651077304, 'lr': 0.02733582665921887, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:54:05,489]\u001b[0m Trial 54 finished with value: 0.9835034013605443 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 18, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 35, 'dropout_lin0': 0.15257463448097447, 'lr': 0.01563074000344834, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:54:28,383]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:54:51,395]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:56:42,917]\u001b[0m Trial 57 finished with value: 0.9828231292517007 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 17, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 16, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 65, 'dropout_lin0': 0.10004763149721863, 'lr': 0.055566942749847616, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:58:38,132]\u001b[0m Trial 58 finished with value: 0.9795918367346939 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 17, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 16, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 2, 'n_units_lin0': 29, 'dropout_lin0': 0.11140161179088559, 'n_units_lin1': 158, 'dropout_lin1': 0.23187140867689365, 'lr': 0.05802681978039704, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:59:22,650]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 13:59:45,845]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:00:53,339]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:01:16,395]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:01:39,259]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:02:00,176]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:03:55,003]\u001b[0m Trial 65 finished with value: 0.9809523809523809 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 20, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 19, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 57, 'dropout_lin0': 0.41989221852358616, 'lr': 0.03271320834547873, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 17 with value: 0.9843537414965986.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:04:16,180]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:04:59,239]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:06:40,378]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:06:59,626]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:07:43,822]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:09:31,233]\u001b[0m Trial 71 finished with value: 0.9855442176870748 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 11, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 52, 'dropout_lin0': 0.2609985287692919, 'lr': 0.026268513076369408, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 71 with value: 0.9855442176870748.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:11:17,534]\u001b[0m Trial 72 finished with value: 0.9828231292517007 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 11, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 18, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 45, 'dropout_lin0': 0.273417274902338, 'lr': 0.02863675207295773, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 71 with value: 0.9855442176870748.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:11:40,254]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:12:22,851]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:14:13,649]\u001b[0m Trial 75 finished with value: 0.9840136054421769 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 11, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 20, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 61, 'dropout_lin0': 0.3095829055531072, 'lr': 0.013972625767610497, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 71 with value: 0.9855442176870748.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:14:35,205]\u001b[0m Trial 76 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 14:15:39,349]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:16:01,295]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:16:23,586]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:16:44,033]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:17:05,985]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:17:27,511]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:19:14,195]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:19:35,603]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:19:57,021]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:20:20,859]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:21:58,816]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:22:20,430]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:24:07,317]\u001b[0m Trial 89 finished with value: 0.9799319727891157 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 13, 'kernel_conv0_even': 2, 'kernel_conv0_odd': 5, 'out_ch_conv1': 19, 'kernel_conv1_even': 2, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 75, 'dropout_lin0': 0.20570469393089846, 'lr': 0.058176871625290165, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 71 with value: 0.9855442176870748.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:24:28,393]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:26:14,368]\u001b[0m Trial 91 finished with value: 0.9739795918367347 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 10, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 19, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 68, 'dropout_lin0': 0.557462201649651, 'lr': 0.02783908920001747, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 71 with value: 0.9855442176870748.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:27:19,529]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:27:39,075]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:29:25,076]\u001b[0m Trial 94 finished with value: 0.9785714285714285 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 10, 'kernel_conv0_even': 4, 'kernel_conv0_odd': 7, 'out_ch_conv1': 20, 'kernel_conv1_even': 6, 'kernel_conv1_odd': 5, 'n_linear_layers': 1, 'n_units_lin0': 60, 'dropout_lin0': 0.43469908806828306, 'lr': 0.04493505134254769, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 71 with value: 0.9855442176870748.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:29:46,920]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:30:09,333]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:31:48,262]\u001b[0m Trial 97 finished with value: 0.9772108843537415 and parameters: {'n_conv_layers': 2, 'out_ch_conv0': 8, 'kernel_conv0_even': 6, 'kernel_conv0_odd': 5, 'out_ch_conv1': 9, 'kernel_conv1_even': 4, 'kernel_conv1_odd': 3, 'n_linear_layers': 1, 'n_units_lin0': 79, 'dropout_lin0': 0.12298798750728508, 'lr': 0.05372922317756365, 'batch_size': 10, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 71 with value: 0.9855442176870748.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:32:07,921]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 14:32:30,161]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# instantiate optuna study\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "# Optimise hyperparameters will try {n_trials} param combinations or till {timeout} seconds is hit\n",
    "study.optimize(objective, n_trials=100)  # , timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1773575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  67\n",
      "  Number of complete trials:  33\n",
      "Best trial:\n",
      "  Validation Accuracy:  0.9855442176870748\n",
      "  Params: \n",
      "    n_conv_layers: 2\n",
      "    out_ch_conv0: 11\n",
      "    kernel_conv0_even: 6\n",
      "    kernel_conv0_odd: 5\n",
      "    out_ch_conv1: 20\n",
      "    kernel_conv1_even: 4\n",
      "    kernel_conv1_odd: 3\n",
      "    n_linear_layers: 1\n",
      "    n_units_lin0: 52\n",
      "    dropout_lin0: 0.2609985287692919\n",
      "    lr: 0.026268513076369408\n",
      "    batch_size: 10\n",
      "    n_epochs: 5\n",
      "    optimizer: SGD\n"
     ]
    }
   ],
   "source": [
    "#display study results\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"  Validation Accuracy: \", best_trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96442901",
   "metadata": {},
   "source": [
    "**Train Final Model Using Tuned Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35abc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataloader(df, my_batchsize, my_shuffle, blind_test = False):\n",
    "    \"\"\"\n",
    "    Function to format dataframe as dataloader\n",
    "    :param df: dataframe\n",
    "    :param blind_test: true if df has no labels\n",
    "    :param my_batchsize: batch size for dataloader\n",
    "    :return: dataloader\n",
    "    \"\"\"\n",
    "    data = MyDataset(df, 'label', blind_test)\n",
    "    my_dataloader = DataLoader(data, batch_size=my_batchsize, shuffle=my_shuffle)\n",
    "\n",
    "    return my_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ff7352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(my_params):\n",
    "    \"\"\"\n",
    "    Train final model using tuned hyperparameters from best Optuna trial\n",
    "    :param my_params: dictionary of parameters from Optuna trial object that had best validation accuracy\n",
    "\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate model\n",
    "    model = define_model(my_params)\n",
    "\n",
    "    # Instantiate optimizer\n",
    "    optimizer_name = my_params['optimizer']\n",
    "    lr = my_params['lr']\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # get data\n",
    "    train_dataloader = df_to_dataloader(training_df, my_batchsize=my_params['batch_size'],\n",
    "                                                  my_shuffle=True)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(my_params['n_epochs']):\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # set datatype for compatibility with nn.\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "\n",
    "            # calculate model output and resulting loss\n",
    "            model_output = model(X)  # tensor. size=(batch_size x n_classes)\n",
    "            loss_fn = nn.CrossEntropyLoss()  # instantiate loss function\n",
    "            loss = loss_fn(model_output, y)\n",
    "\n",
    "            # Backpropagation to update model weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "993a43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_trial.params\n",
    "final_model = train_final_model(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa6625",
   "metadata": {},
   "source": [
    "**Evaluate final training accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "252b5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(model, df):\n",
    "    \"\"\"\n",
    "    Function to run trained and tuned model on provided dataframe to obtain predictions and evaluate\n",
    "    accuracy\n",
    "\n",
    "    :param model: trained model\n",
    "    :param df: dataframe including features and target/label\n",
    "\n",
    "    :return: accuracy\n",
    "    \"\"\"\n",
    "    my_dataloader = df_to_dataloader(df, my_batchsize=10, my_shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(my_dataloader):\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "\n",
    "            # calculate model output and total number of correct predictions for this batch\n",
    "            model_output = model(X)\n",
    "            pred = torch.argmax(model_output, dim=1)  # prediction = class with highest output value\n",
    "            correct += count_correct(pred, y)\n",
    "\n",
    "    accuracy = correct / len(my_dataloader.dataset)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cdc7ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final Training Accuracy: 0.9901020408163266\n"
     ]
    }
   ],
   "source": [
    "train_acc = predict_and_evaluate(final_model, training_df)\n",
    "print(f\"  Final Training Accuracy: {train_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccaaf4",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>Mock Test\n",
    "Evaluate accuracy on mock-test data - i.e. portion of training data which was reserved at the start, and **not** used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "403a73b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test Accuracy: 0.9847619047619047\n"
     ]
    }
   ],
   "source": [
    "test_acc = predict_and_evaluate(final_model, mytest_df)\n",
    "print(f\"  Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa2281",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb6f457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter filename to save model under: cnn_2\n"
     ]
    }
   ],
   "source": [
    "filename = input(\"Enter filename to save model under: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08850b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = r\"Convolutional Neural Network\" + \"\\\\\" + filename + \".pth\"\n",
    "torch.save(final_model, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdeeb4a",
   "metadata": {},
   "source": [
    "## <font color = 'orange'>Test\n",
    "Evaluate accuracy on kaggle test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b76000bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa5086ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataloader\n",
    "test_dataloader = df_to_dataloader(test_df, my_batchsize=100, my_shuffle=False, blind_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d806ff5",
   "metadata": {},
   "source": [
    "**Import & Run Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "470c3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter filename of CNN model filename: cnn_2\n"
     ]
    }
   ],
   "source": [
    "# Import trained model\n",
    "filename2 = input(\"Enter filename of CNN model filename: \")\n",
    "fp = r\"Convolutional Neural Network\" + \"\\\\\" + filename2 + \".pth\"\n",
    "model = torch.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afe91cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch, X in enumerate(test_dataloader):\n",
    "        X = X.float()\n",
    "        model_output = model(X)\n",
    "        pred = torch.argmax(model_output, dim=1).numpy()  # prediction = class with highest output value\n",
    "        if batch==0:\n",
    "            predictions = pred\n",
    "        else:\n",
    "            predictions = np.append(predictions, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c943124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format in kaggle's required format\n",
    "image_id = np.arange(1,len(predictions)+1)\n",
    "predictions_df = pd.DataFrame.from_dict(data={'ImageId': image_id, 'Label': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac8e3289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "311ed76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "fp = r\"Convolutional Neural Network\\my_submission_\" + filename2 + \".csv\"\n",
    "predictions_df.to_csv(fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140eab04",
   "metadata": {},
   "source": [
    "**<font color = 'orange'>Test results from Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48561791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_1</td>\n",
       "      <td>0.97414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_2</td>\n",
       "      <td>0.97232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  accuracy\n",
       "0  cnn_1   0.97414\n",
       "1  cnn_2   0.97232"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_results = {'cnn_1':0.97414, 'cnn_2':0.97232}\n",
    "\n",
    "myresults_df = pd.DataFrame.from_dict(my_results, 'index').reset_index().rename({'index':'model',0:'accuracy'},axis=1)\n",
    "myresults_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
