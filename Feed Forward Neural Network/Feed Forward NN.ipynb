{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83da691a",
   "metadata": {},
   "source": [
    "Environment: pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a49924",
   "metadata": {},
   "source": [
    "# <font color = 'purple'> Feed Forward Neural Network\n",
    "In this notebook, we build and tune a feed forward neural network to classify the MNIST samples as one of 10 digits: 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33b8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53218f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sharo\\\\Documents\\\\Postgrad\\\\My Data Science Portfolio\\\\Classification - MNIST'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\sharo\\Documents\\Postgrad\\My Data Science Portfolio\\Classification - MNIST\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f875da",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01af1cb",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Import Training Data & Reserve Mock-Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260e0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_df(fp, label_colname, my_seed=None):\n",
    "    \"\"\"\n",
    "    Function to import raw data, carry out pre-processing, and split into training and test datasets.\n",
    "    Test data will be reserved for final evaluation of model performance (i.e. not for hyperparameter tuning)\n",
    "\n",
    "    :param fp: filepath\n",
    "    :param label_colname: name of column containing labels\n",
    "    :param my_seed: integer to be used to fix random state for train_test_split\n",
    "\n",
    "    :return: tuple of dataframes - training_df, test_df\n",
    "    \"\"\"\n",
    "\n",
    "    # import data\n",
    "    df = pd.read_csv(fp)\n",
    "\n",
    "    # Standard scaling of features \n",
    "    scaler = StandardScaler()\n",
    "    df[df.drop(columns=label_colname).columns] = scaler.fit_transform(df[df.drop(columns=label_colname).columns])\n",
    "\n",
    "    # separate into training & test datasets.\n",
    "    # Stratification is used to ensure training and test sets have representative proportions of all classes\n",
    "    # Given the large size of the dataset, we are able to use reserve a slightly larger test set (30%) whilst\n",
    "    # retaining adequate data for training\n",
    "    training_df, test_df = train_test_split(df, test_size=0.3, random_state=my_seed, stratify=df[label_colname])\n",
    "\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ad9ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the filtered training data - i.e. after removing pixels which are always zero\n",
    "training_df, mytest_df = get_train_test_df(\"train_filtered.csv\", label_colname='label', my_seed = my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2cbb1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26260</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.005281</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.005629</td>\n",
       "      <td>-0.009321</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060228</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.042793</td>\n",
       "      <td>-0.034737</td>\n",
       "      <td>-0.02527</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>-0.011473</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>-0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.005281</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.005629</td>\n",
       "      <td>-0.009321</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060228</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.042793</td>\n",
       "      <td>-0.034737</td>\n",
       "      <td>-0.02527</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>-0.011473</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>-0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36257</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.005281</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.005629</td>\n",
       "      <td>-0.009321</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060228</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.042793</td>\n",
       "      <td>-0.034737</td>\n",
       "      <td>-0.02527</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>-0.011473</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>-0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10353</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.005281</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.005629</td>\n",
       "      <td>-0.009321</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060228</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.042793</td>\n",
       "      <td>-0.034737</td>\n",
       "      <td>-0.02527</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>-0.011473</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>-0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17347</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.005281</td>\n",
       "      <td>-0.006878</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.005629</td>\n",
       "      <td>-0.009321</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060228</td>\n",
       "      <td>-0.056359</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.042793</td>\n",
       "      <td>-0.034737</td>\n",
       "      <td>-0.02527</td>\n",
       "      <td>-0.018026</td>\n",
       "      <td>-0.011473</td>\n",
       "      <td>-0.009099</td>\n",
       "      <td>-0.006897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 709 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label   pixel12   pixel13  pixel14  pixel15  pixel32   pixel33  \\\n",
       "26260      4 -0.005281 -0.006878 -0.00488 -0.00488 -0.00488 -0.005629   \n",
       "6235       2 -0.005281 -0.006878 -0.00488 -0.00488 -0.00488 -0.005629   \n",
       "36257      7 -0.005281 -0.006878 -0.00488 -0.00488 -0.00488 -0.005629   \n",
       "10353      1 -0.005281 -0.006878 -0.00488 -0.00488 -0.00488 -0.005629   \n",
       "17347      0 -0.005281 -0.006878 -0.00488 -0.00488 -0.00488 -0.005629   \n",
       "\n",
       "        pixel34  pixel35   pixel36  ...  pixel770  pixel771  pixel772  \\\n",
       "26260 -0.009321  -0.0118 -0.016306  ... -0.060228 -0.056359 -0.051608   \n",
       "6235  -0.009321  -0.0118 -0.016306  ... -0.060228 -0.056359 -0.051608   \n",
       "36257 -0.009321  -0.0118 -0.016306  ... -0.060228 -0.056359 -0.051608   \n",
       "10353 -0.009321  -0.0118 -0.016306  ... -0.060228 -0.056359 -0.051608   \n",
       "17347 -0.009321  -0.0118 -0.016306  ... -0.060228 -0.056359 -0.051608   \n",
       "\n",
       "       pixel773  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \n",
       "26260 -0.042793 -0.034737  -0.02527 -0.018026 -0.011473 -0.009099 -0.006897  \n",
       "6235  -0.042793 -0.034737  -0.02527 -0.018026 -0.011473 -0.009099 -0.006897  \n",
       "36257 -0.042793 -0.034737  -0.02527 -0.018026 -0.011473 -0.009099 -0.006897  \n",
       "10353 -0.042793 -0.034737  -0.02527 -0.018026 -0.011473 -0.009099 -0.006897  \n",
       "17347 -0.042793 -0.034737  -0.02527 -0.018026 -0.011473 -0.009099 -0.006897  \n",
       "\n",
       "[5 rows x 709 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553af74b",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>Train Model\n",
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a91ef328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of features: 708\n",
      "No. of classes: 10\n"
     ]
    }
   ],
   "source": [
    "n_features = training_df.shape[1] - 1  # number of features in feature matrix.\n",
    "n_classes = len(training_df['label'].unique())  # number of unique classes.\n",
    "\n",
    "print(f\"No. of features: {n_features}\")\n",
    "print(f\"No. of classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da16ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): # inherits properties of pytorch Dataset class\n",
    "    def __init__(self, dataframe, label_colname=None, blind_test=False):\n",
    "        \"\"\"\n",
    "            Class initialisation\n",
    "            :param dataframe: pandas dataframe including features and labels\n",
    "            :param label_colname: name of column containing labels\n",
    "            :param blind_test: Boolean. True means dataframe does not include labels (i.e. test set)\n",
    "            \"\"\"\n",
    "        self.blind_test = blind_test\n",
    "\n",
    "        if blind_test:  # for blind test (i.e. no label, self.labels does not exist)\n",
    "            self.features = dataframe.to_numpy()\n",
    "        else:\n",
    "            self.features = dataframe.drop(columns=[label_colname]).to_numpy()\n",
    "            self.labels = dataframe[label_colname].to_numpy()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return: length of dataset\n",
    "        \"\"\"\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetches features and label(s) at requested index\n",
    "        :param idx: requested index\n",
    "        :return: tuple of numpy arrays - batch_features, batch_labels. For blind test, return only batch_features\n",
    "        \"\"\"\n",
    "        batch_features = self.features[idx,:]\n",
    "        if self.blind_test:\n",
    "            return batch_features\n",
    "        else:\n",
    "            batch_labels = self.labels[idx]\n",
    "            return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb4892a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_dataloader(training_df, my_batchsize, label_colname, my_seed = None):\n",
    "    \"\"\"\n",
    "    Function to split training data into training and validation subsets and format as dataloaders\n",
    "    Model performance on validation set will be used for hyperparameter tuning.\n",
    "\n",
    "    :param training_df: dataframe with full set of training data\n",
    "    :param my_batchsize: batch size for pytorch DataLoader\n",
    "    :param label_colname: name of column containing labels\n",
    "    :param my_seed: optional integer to fix train test split random state\n",
    "\n",
    "    :return: tuple of pytorch DataLoaders - train_dataloader, val_dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    # separate into training & validation datasets\n",
    "    train_data, val_data = train_test_split(training_df, test_size = 0.2, random_state = my_seed, stratify=training_df[label_colname])\n",
    "\n",
    "    #format as pytorch dataloader\n",
    "    train, val = MyDataset(train_data, label_colname), MyDataset(val_data, label_colname)\n",
    "    train_dataloader = DataLoader(train, batch_size=my_batchsize, shuffle=True)\n",
    "    val_dataloader = DataLoader(val, batch_size=my_batchsize)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a197dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_correct(predictions, y):\n",
    "    \"\"\"\n",
    "    Counts number of correct predictions in a batch\n",
    "\n",
    "    :param predictions: 1D tensor with predictions\n",
    "    :param y: 1D tensor with true classes\n",
    "\n",
    "    :return: number of correct predictions (pred==y)\n",
    "    \"\"\"\n",
    "    predictions = predictions.numpy()\n",
    "    y = y.numpy()\n",
    "\n",
    "    n_correct = (predictions == y).sum()\n",
    "\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f203ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(trial):\n",
    "    \"\"\"\n",
    "    Set parameters for neural network, optimisation algorithm etc.\n",
    "\n",
    "    :param trial: Optuna trial object\n",
    "\n",
    "    :return: dictionary of parameters:\n",
    "            - n_layers: number of layers in neural network\n",
    "            - n_units_l{i}: number of units in layer i\n",
    "            - dropout_l{i}: dropout probability for layer i (larger = greater regularisation)\n",
    "            - lr: learning rate\n",
    "            - batch_size: batch size\n",
    "            - n_epochs: number of epochs (i.e. number of passes through training data to optimise weights)\n",
    "            - optimiser: optimisation algorithm to be used\n",
    "    \"\"\"\n",
    "    trial.suggest_int(\"n_layers\", 1, 3)\n",
    "\n",
    "    for i in range(trial.params['n_layers']):\n",
    "        trial.suggest_int(f'n_units_l{i}', 2, 20)\n",
    "        trial.suggest_float(f\"dropout_l{i}\", 0.1, 1)\n",
    "\n",
    "    trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    # TODO: try optimising these as well\n",
    "    trial.suggest_int(\"batch_size\", 100, 100)\n",
    "    trial.suggest_int(\"n_epochs\", 5, 5)\n",
    "    trial.suggest_categorical(\"optimizer\", [\"SGD\"])\n",
    "\n",
    "    return trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffa971d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(my_params):\n",
    "    \"\"\"Defines feed-forward neural network based on set parameters\n",
    "\n",
    "    :param my_params: dictionary of parameters (see set_parameters() for full list)\n",
    "\n",
    "    :return: nn model\n",
    "    \"\"\"\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    in_features = n_features  # number of input features for 1st layer = no. of features in feature matrix\n",
    "\n",
    "    for i in range(my_params['n_layers']):\n",
    "        # n_inputs = n_outputs of previous layer, n_outputs=no. of units in that lyr\n",
    "        out_features = my_params[f'n_units_l{i}']\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "\n",
    "        layers.append(nn.ReLU())  # activation function\n",
    "\n",
    "        # drop-out regularisation. (note: drop-out works by zeroing some elements of the tensor. tensor shape is unchanged)\n",
    "        p = my_params[f\"dropout_l{i}\"]\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features  # no. of inputs for next layer = no. of outputs of this layer\n",
    "\n",
    "    layers.append(nn.Linear(in_features, n_classes))  # output layer. No. of outputs = no. of unique classes in dataset\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "243f3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective for Optuna to optimise\n",
    "    :param trial: Optuna trial object\n",
    "    :return: accuracy - fraction of correctly labelled validation points. This is what Optuna seeks to maximise\n",
    "    \"\"\"\n",
    "\n",
    "    #set parameters\n",
    "    my_params = set_parameters(trial)\n",
    "\n",
    "    # Instantiate model\n",
    "    model = define_model(my_params)\n",
    "\n",
    "    # Instantiate optimizer\n",
    "    optimizer_name = my_params['optimizer']\n",
    "    lr = my_params['lr']\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # get data\n",
    "    # TODO: notice for each trial, training and validation sets are different. \n",
    "    #       Hence, differences in performance may not be due to trial parameters alone. \n",
    "    #       Consider implementing cross-validation so that results are less dependent on individual train-test splits\n",
    "    train_dataloader, val_dataloader = get_train_val_dataloader(training_df, \n",
    "                                                                my_batchsize=my_params['batch_size'],\n",
    "                                                                label_colname='label')\n",
    "    # train model\n",
    "    for epoch in range(my_params['n_epochs']):\n",
    "\n",
    "        #train\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # X and y are tensors. X.size() = (batch_size,n_features), y.size()=(batch_size,)\n",
    "            # set datatype for compatibility with nn.\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "\n",
    "            # calculate model output and resulting loss\n",
    "            model_output = model(X)  # tensor. size=(batch_size x n_classes)\n",
    "            loss_fn = nn.CrossEntropyLoss() # instantiate loss function\n",
    "            loss = loss_fn(model_output, y)\n",
    "\n",
    "            # Backpropagation to update model weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validate. We do this at each epoch to facilitate pruning:\n",
    "        # i.e. early termination of trials which are clearly not going to be optimum\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch, (X, y) in enumerate(val_dataloader):\n",
    "                X = X.float()\n",
    "                y = y.long()\n",
    "\n",
    "                # calculate model output and total number of correct predictions for this batch\n",
    "                model_output = model(X)\n",
    "                pred = torch.argmax(model_output, dim=1)  # prediction = class with highest output value\n",
    "                correct += count_correct(pred, y)\n",
    "\n",
    "        accuracy = correct / len(val_dataloader.dataset)\n",
    "\n",
    "        # report accuracy to allow Optuna to decide whether to prune this trial\n",
    "        trial.report(accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy  # return final validation accuracy after all epochs (unless pruned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c969717",
   "metadata": {},
   "source": [
    "**Optimise Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3a9c532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 12:14:45,916]\u001b[0m A new study created in memory with name: no-name-b9e41578-f6a4-40e4-a76a-65ce55030d9c\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:14:53,857]\u001b[0m Trial 0 finished with value: 0.09642857142857143 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'dropout_l0': 0.5779361244591678, 'n_units_l1': 10, 'dropout_l1': 0.695174009363966, 'n_units_l2': 6, 'dropout_l2': 0.6302159656807829, 'lr': 0.0005139775674364189, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.09642857142857143.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:01,699]\u001b[0m Trial 1 finished with value: 0.11156462585034013 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_l0': 0.4858848631707058, 'n_units_l1': 19, 'dropout_l1': 0.9982793268743696, 'n_units_l2': 4, 'dropout_l2': 0.7491634181909738, 'lr': 0.03183177835097524, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 1 with value: 0.11156462585034013.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:08,967]\u001b[0m Trial 2 finished with value: 0.11598639455782313 and parameters: {'n_layers': 2, 'n_units_l0': 3, 'dropout_l0': 0.3452074312555725, 'n_units_l1': 16, 'dropout_l1': 0.20329180142584852, 'lr': 0.0001977450361635563, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.11598639455782313.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:17,171]\u001b[0m Trial 3 finished with value: 0.09710884353741496 and parameters: {'n_layers': 3, 'n_units_l0': 18, 'dropout_l0': 0.33331009324332944, 'n_units_l1': 3, 'dropout_l1': 0.4062498932482175, 'n_units_l2': 14, 'dropout_l2': 0.8351736925103225, 'lr': 0.0014402953560126365, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.11598639455782313.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:25,100]\u001b[0m Trial 4 finished with value: 0.09030612244897959 and parameters: {'n_layers': 3, 'n_units_l0': 3, 'dropout_l0': 0.6769867113730258, 'n_units_l1': 13, 'dropout_l1': 0.5368610819168698, 'n_units_l2': 5, 'dropout_l2': 0.7607585192030772, 'lr': 0.0004956005614390872, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.11598639455782313.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:32,851]\u001b[0m Trial 5 finished with value: 0.7003401360544218 and parameters: {'n_layers': 2, 'n_units_l0': 12, 'dropout_l0': 0.15845535660269205, 'n_units_l1': 19, 'dropout_l1': 0.9205051609682967, 'lr': 0.061864108538329514, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.7003401360544218.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:40,406]\u001b[0m Trial 6 finished with value: 0.4608843537414966 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'dropout_l0': 0.5692694252561478, 'n_units_l1': 17, 'dropout_l1': 0.2992332617724237, 'lr': 0.0034939598401218085, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.7003401360544218.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:47,451]\u001b[0m Trial 7 finished with value: 0.9066326530612245 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.47590665976979185, 'lr': 0.026525665269383505, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 7 with value: 0.9066326530612245.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:49,265]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:54,280]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:15:56,023]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:03,670]\u001b[0m Trial 11 finished with value: 0.9187074829931973 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.11138370524700397, 'lr': 0.08788404481376533, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:10,593]\u001b[0m Trial 12 finished with value: 0.9054421768707483 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.10970819106432257, 'lr': 0.013519929489943502, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:17,497]\u001b[0m Trial 13 finished with value: 0.9027210884353741 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.34119493117474925, 'lr': 0.08567810570456455, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:24,197]\u001b[0m Trial 14 finished with value: 0.8875850340136054 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.25902682013462763, 'lr': 0.010602502162658702, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:30,975]\u001b[0m Trial 15 finished with value: 0.8809523809523809 and parameters: {'n_layers': 1, 'n_units_l0': 12, 'dropout_l0': 0.45905325796409424, 'lr': 0.01594937420564636, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:37,889]\u001b[0m Trial 16 finished with value: 0.8773809523809524 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.7792443170200285, 'lr': 0.09465140669620854, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:39,583]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:41,409]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:48,438]\u001b[0m Trial 19 finished with value: 0.8501700680272108 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'dropout_l0': 0.6637528205717382, 'lr': 0.02875432695126675, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:50,238]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:16:57,215]\u001b[0m Trial 21 finished with value: 0.9062925170068027 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.1149923809771834, 'lr': 0.02745297181412669, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:04,171]\u001b[0m Trial 22 finished with value: 0.9130952380952381 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'dropout_l0': 0.110471850253216, 'lr': 0.0323040960753105, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:11,232]\u001b[0m Trial 23 finished with value: 0.9017006802721088 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'dropout_l0': 0.2689743949263246, 'lr': 0.04692155105327745, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:12,876]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:19,864]\u001b[0m Trial 25 finished with value: 0.9137755102040817 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.2001990863344313, 'lr': 0.0216439321368287, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:21,723]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:29,016]\u001b[0m Trial 27 finished with value: 0.8993197278911564 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.17924129218476142, 'lr': 0.018382253387295818, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:30,690]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:32,507]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:39,732]\u001b[0m Trial 30 finished with value: 0.8993197278911564 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'dropout_l0': 0.2886456475916569, 'lr': 0.09732125067041524, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:46,866]\u001b[0m Trial 31 finished with value: 0.9003401360544218 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.5086325220228611, 'lr': 0.026186929069271617, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 11 with value: 0.9187074829931973.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:17:53,868]\u001b[0m Trial 32 finished with value: 0.9244897959183673 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.1603742370539536, 'lr': 0.039256529226525415, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 32 with value: 0.9244897959183673.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 12:18:00,774]\u001b[0m Trial 33 finished with value: 0.9136054421768708 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.16933007869741895, 'lr': 0.0405992582968844, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 32 with value: 0.9244897959183673.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:07,603]\u001b[0m Trial 34 finished with value: 0.911734693877551 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.2052816430800662, 'lr': 0.043341510061566106, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 32 with value: 0.9244897959183673.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:09,286]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:11,048]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:12,914]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:14,651]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:16,602]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:20,917]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:27,793]\u001b[0m Trial 41 finished with value: 0.920578231292517 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.14037729199030036, 'lr': 0.03745558970890141, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 32 with value: 0.9244897959183673.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:34,607]\u001b[0m Trial 42 finished with value: 0.9175170068027211 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.1544185014652117, 'lr': 0.03772588091324833, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 32 with value: 0.9244897959183673.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:36,325]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:38,012]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:39,788]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:47,169]\u001b[0m Trial 46 finished with value: 0.9299319727891157 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'dropout_l0': 0.10080952891895395, 'lr': 0.06642639721774925, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:18:53,852]\u001b[0m Trial 47 finished with value: 0.9107142857142857 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'dropout_l0': 0.11464164157997822, 'lr': 0.061150475945910526, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:01,327]\u001b[0m Trial 48 finished with value: 0.9136054421768708 and parameters: {'n_layers': 2, 'n_units_l0': 13, 'dropout_l0': 0.10262031465150523, 'n_units_l1': 20, 'dropout_l1': 0.2538665760221016, 'lr': 0.07306132247007215, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:02,952]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:04,602]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:11,701]\u001b[0m Trial 51 finished with value: 0.9112244897959184 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.22358115631091074, 'lr': 0.024167774649884455, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:18,798]\u001b[0m Trial 52 finished with value: 0.9188775510204081 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.14588944967262607, 'lr': 0.09230630395050288, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:25,671]\u001b[0m Trial 53 finished with value: 0.920578231292517 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.13911061015563228, 'lr': 0.0707064958078522, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:32,395]\u001b[0m Trial 54 finished with value: 0.9210884353741496 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.13304409921359542, 'lr': 0.08608607277445698, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:34,022]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:36,990]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:44,225]\u001b[0m Trial 57 finished with value: 0.9202380952380952 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.1408820955358673, 'lr': 0.0636460198854701, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:46,360]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:53,067]\u001b[0m Trial 59 finished with value: 0.9146258503401361 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.27424936056867283, 'lr': 0.053794141801362244, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:19:59,915]\u001b[0m Trial 60 finished with value: 0.9122448979591836 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'dropout_l0': 0.1796147633209379, 'lr': 0.035180775399413264, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:06,659]\u001b[0m Trial 61 finished with value: 0.920578231292517 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.1292132020180286, 'lr': 0.07138536604361101, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:08,301]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:10,033]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:17,331]\u001b[0m Trial 64 finished with value: 0.9149659863945578 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'dropout_l0': 0.1300260212667665, 'lr': 0.042736119496144656, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:19,010]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:20,663]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:22,392]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:28,277]\u001b[0m Trial 68 finished with value: 0.9200680272108843 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.10164506267385454, 'lr': 0.04858875933696916, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:32,605]\u001b[0m Trial 69 finished with value: 0.919047619047619 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.131967086909461, 'lr': 0.08003895665242725, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:36,908]\u001b[0m Trial 70 finished with value: 0.9158163265306123 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.20054651139401158, 'lr': 0.05696424756718449, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:41,312]\u001b[0m Trial 71 finished with value: 0.9210884353741496 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.10125622880183346, 'lr': 0.04660582373210142, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:42,435]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:43,575]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:48,127]\u001b[0m Trial 74 finished with value: 0.9195578231292517 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.13063998960618248, 'lr': 0.046313451561403804, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:52,434]\u001b[0m Trial 75 finished with value: 0.9224489795918367 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.16963474986966176, 'lr': 0.0794016997616297, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 46 with value: 0.9299319727891157.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:20:56,637]\u001b[0m Trial 76 finished with value: 0.9324829931972789 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.16620345906282002, 'lr': 0.09563274157644432, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 12:21:00,930]\u001b[0m Trial 77 finished with value: 0.9229591836734694 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.2114677247837765, 'lr': 0.09717617082720979, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:02,106]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:04,741]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:09,146]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:13,472]\u001b[0m Trial 81 finished with value: 0.922108843537415 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.1693456553503564, 'lr': 0.05574670271836947, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:17,777]\u001b[0m Trial 82 finished with value: 0.9258503401360544 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.16256610957186032, 'lr': 0.054653899363573615, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:22,084]\u001b[0m Trial 83 finished with value: 0.9181972789115647 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.16840750772357746, 'lr': 0.05126053083775438, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:26,362]\u001b[0m Trial 84 finished with value: 0.9204081632653062 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.2356516777423424, 'lr': 0.028098169533100303, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:28,977]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:30,034]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:31,192]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:35,514]\u001b[0m Trial 88 finished with value: 0.926530612244898 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.16359705867903615, 'lr': 0.08386875069252277, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:39,738]\u001b[0m Trial 89 finished with value: 0.9253401360544218 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.16581138462486805, 'lr': 0.08215600732168887, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:40,794]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:45,019]\u001b[0m Trial 91 finished with value: 0.9319727891156463 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.16388315512865123, 'lr': 0.08760127332460568, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:49,414]\u001b[0m Trial 92 finished with value: 0.9294217687074829 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.17173564191624946, 'lr': 0.08094353007290257, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:53,775]\u001b[0m Trial 93 finished with value: 0.9231292517006803 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.16125679777721436, 'lr': 0.09878248305238742, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:21:58,291]\u001b[0m Trial 94 finished with value: 0.926530612244898 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.216258672266753, 'lr': 0.09917059791593028, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:02,568]\u001b[0m Trial 95 finished with value: 0.9280612244897959 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1892210349192916, 'lr': 0.06261555709213137, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:06,849]\u001b[0m Trial 96 finished with value: 0.9227891156462585 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.23190325340046858, 'lr': 0.06195123688853384, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:11,080]\u001b[0m Trial 97 finished with value: 0.923469387755102 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.18521375577366464, 'lr': 0.039183810358841976, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:12,188]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:13,285]\u001b[0m Trial 99 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:17,669]\u001b[0m Trial 100 finished with value: 0.9263605442176871 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.18753342144331325, 'lr': 0.07841075268752569, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:22,068]\u001b[0m Trial 101 finished with value: 0.9215986394557824 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.19537553757531226, 'lr': 0.08281912460301014, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:26,467]\u001b[0m Trial 102 finished with value: 0.925 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.15604419013966703, 'lr': 0.06088822458274364, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:30,870]\u001b[0m Trial 103 finished with value: 0.9292517006802721 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.11876769945362381, 'lr': 0.06012368976644997, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:35,282]\u001b[0m Trial 104 finished with value: 0.9202380952380952 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.21465212211678122, 'lr': 0.0789087279033408, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:36,348]\u001b[0m Trial 105 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:37,535]\u001b[0m Trial 106 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:38,688]\u001b[0m Trial 107 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:39,755]\u001b[0m Trial 108 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:44,179]\u001b[0m Trial 109 finished with value: 0.9301020408163265 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.14837424773165508, 'lr': 0.08128809294714504, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:48,457]\u001b[0m Trial 110 finished with value: 0.9253401360544218 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'dropout_l0': 0.12366704704493378, 'lr': 0.0653389237856284, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:52,696]\u001b[0m Trial 111 finished with value: 0.9238095238095239 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'dropout_l0': 0.11801676618943963, 'lr': 0.06741822888281793, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:22:56,957]\u001b[0m Trial 112 finished with value: 0.9258503401360544 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.14525668938014888, 'lr': 0.050389845689487726, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:01,237]\u001b[0m Trial 113 finished with value: 0.9197278911564626 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.14678020702614583, 'lr': 0.050912735087179854, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:05,501]\u001b[0m Trial 114 finished with value: 0.9193877551020408 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.18902636357999555, 'lr': 0.0858069506553681, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 12:23:09,756]\u001b[0m Trial 115 finished with value: 0.9284013605442177 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.14836953597807745, 'lr': 0.04229924337542643, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:13,985]\u001b[0m Trial 116 finished with value: 0.9268707482993197 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1487183101847986, 'lr': 0.04097964079732403, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:15,062]\u001b[0m Trial 117 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:19,508]\u001b[0m Trial 118 finished with value: 0.9222789115646258 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1166454256797414, 'lr': 0.029964395048632846, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:23,735]\u001b[0m Trial 119 finished with value: 0.9241496598639456 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'dropout_l0': 0.14721629581311513, 'lr': 0.09807008664228647, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:24,816]\u001b[0m Trial 120 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:29,264]\u001b[0m Trial 121 finished with value: 0.9243197278911565 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.14210403618190623, 'lr': 0.07227106188352068, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:30,265]\u001b[0m Trial 122 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:34,705]\u001b[0m Trial 123 finished with value: 0.9241496598639456 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.16415829965192813, 'lr': 0.05622921318657245, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 76 with value: 0.9324829931972789.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:38,896]\u001b[0m Trial 124 finished with value: 0.9363945578231293 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10169405572379225, 'lr': 0.04565161940573097, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:40,039]\u001b[0m Trial 125 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:41,145]\u001b[0m Trial 126 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:45,557]\u001b[0m Trial 127 finished with value: 0.9282312925170068 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'dropout_l0': 0.13285707483580841, 'lr': 0.08038563180352505, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:49,832]\u001b[0m Trial 128 finished with value: 0.9255102040816326 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'dropout_l0': 0.13636129291146515, 'lr': 0.04540663650271368, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:54,134]\u001b[0m Trial 129 finished with value: 0.9297619047619048 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.11851342068825345, 'lr': 0.08437243391037486, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:23:58,479]\u001b[0m Trial 130 finished with value: 0.9312925170068027 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10325747587561723, 'lr': 0.09808635399632937, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:02,766]\u001b[0m Trial 131 finished with value: 0.9280612244897959 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1194874195548257, 'lr': 0.06607491571368367, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:07,040]\u001b[0m Trial 132 finished with value: 0.9304421768707483 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10152015317628221, 'lr': 0.06504766721898278, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:11,235]\u001b[0m Trial 133 finished with value: 0.9284013605442177 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10376983383323331, 'lr': 0.06725733831768393, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:15,543]\u001b[0m Trial 134 finished with value: 0.9331632653061225 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.11416536880749736, 'lr': 0.07171137092143616, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:19,860]\u001b[0m Trial 135 finished with value: 0.9318027210884354 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10195541808527694, 'lr': 0.07873826494871236, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:20,894]\u001b[0m Trial 136 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:25,237]\u001b[0m Trial 137 finished with value: 0.9258503401360544 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.11625845415868011, 'lr': 0.05500786018424881, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:29,508]\u001b[0m Trial 138 finished with value: 0.9335034013605442 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1070239394222125, 'lr': 0.09961689104841173, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:33,827]\u001b[0m Trial 139 finished with value: 0.930952380952381 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10087413122012089, 'lr': 0.09936993699246618, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:34,848]\u001b[0m Trial 140 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:39,079]\u001b[0m Trial 141 finished with value: 0.930952380952381 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1067154988598736, 'lr': 0.08513499966052956, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:43,454]\u001b[0m Trial 142 finished with value: 0.9335034013605442 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10205708273014516, 'lr': 0.08576666089832129, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:47,709]\u001b[0m Trial 143 finished with value: 0.9331632653061225 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.12945356931788488, 'lr': 0.0847625895612693, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 124 with value: 0.9363945578231293.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:51,998]\u001b[0m Trial 144 finished with value: 0.938265306122449 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1304193070818448, 'lr': 0.08749252019850264, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:24:56,260]\u001b[0m Trial 145 finished with value: 0.9369047619047619 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.10329302403833884, 'lr': 0.09794888708088685, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:00,701]\u001b[0m Trial 146 finished with value: 0.9318027210884354 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.132069367760056, 'lr': 0.09869769922946328, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:05,023]\u001b[0m Trial 147 finished with value: 0.9336734693877551 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.13147810874124868, 'lr': 0.09981843265566434, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 12:25:09,354]\u001b[0m Trial 148 finished with value: 0.9329931972789116 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.13097693500982305, 'lr': 0.0984315854157318, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:13,632]\u001b[0m Trial 149 finished with value: 0.9312925170068027 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1320810720656615, 'lr': 0.09991899175708975, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:17,954]\u001b[0m Trial 150 finished with value: 0.9268707482993197 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.13196830353763261, 'lr': 0.09576368327313779, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:22,280]\u001b[0m Trial 151 finished with value: 0.9319727891156463 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.12366822612845743, 'lr': 0.09926750500664634, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:26,538]\u001b[0m Trial 152 finished with value: 0.9243197278911565 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.13190028474998272, 'lr': 0.07619512583319542, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:28,369]\u001b[0m Trial 153 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:32,752]\u001b[0m Trial 154 finished with value: 0.9343537414965987 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.15930479073855366, 'lr': 0.09966382977235987, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:37,124]\u001b[0m Trial 155 finished with value: 0.9260204081632653 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.1588019671176441, 'lr': 0.07848712335616877, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:41,432]\u001b[0m Trial 156 finished with value: 0.9355442176870749 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1349609840955292, 'lr': 0.06939483217667612, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:42,506]\u001b[0m Trial 157 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:47,111]\u001b[0m Trial 158 finished with value: 0.9253401360544218 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.14926088373519925, 'lr': 0.06073521321035786, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:48,261]\u001b[0m Trial 159 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:52,548]\u001b[0m Trial 160 finished with value: 0.9292517006802721 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.15924405875868897, 'lr': 0.05223966800715121, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:25:56,912]\u001b[0m Trial 161 finished with value: 0.9299319727891157 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.12697816109030466, 'lr': 0.08094065958124103, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:01,285]\u001b[0m Trial 162 finished with value: 0.9287414965986395 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.13465759308859057, 'lr': 0.0994063953536853, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:05,594]\u001b[0m Trial 163 finished with value: 0.9277210884353742 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.13653770776441665, 'lr': 0.07169307041504984, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:09,831]\u001b[0m Trial 164 finished with value: 0.9282312925170068 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.1740011654309791, 'lr': 0.08526563831552708, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:10,963]\u001b[0m Trial 165 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:12,092]\u001b[0m Trial 166 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:16,417]\u001b[0m Trial 167 finished with value: 0.9324829931972789 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.15069354377225122, 'lr': 0.08449351659742699, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:17,466]\u001b[0m Trial 168 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:21,746]\u001b[0m Trial 169 finished with value: 0.9284013605442177 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.15160919849300922, 'lr': 0.05555376403473434, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:22,864]\u001b[0m Trial 170 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:27,228]\u001b[0m Trial 171 finished with value: 0.9251700680272109 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.12645123437231232, 'lr': 0.08677471412180811, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:31,489]\u001b[0m Trial 172 finished with value: 0.9304421768707483 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1160128055058084, 'lr': 0.08712805057250525, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:32,549]\u001b[0m Trial 173 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:36,834]\u001b[0m Trial 174 finished with value: 0.9287414965986395 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.13679083326345298, 'lr': 0.09798450358399598, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:37,900]\u001b[0m Trial 175 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:42,235]\u001b[0m Trial 176 finished with value: 0.9370748299319728 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1214862593660296, 'lr': 0.0992196719511928, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:46,598]\u001b[0m Trial 177 finished with value: 0.9251700680272109 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.12245083810420819, 'lr': 0.0715525675693082, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:48,490]\u001b[0m Trial 178 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:53,097]\u001b[0m Trial 179 finished with value: 0.9329931972789116 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.15844623637633942, 'lr': 0.08193296634740291, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:26:56,564]\u001b[0m Trial 180 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:00,832]\u001b[0m Trial 181 finished with value: 0.9294217687074829 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1468985641912781, 'lr': 0.08389206605874064, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:05,121]\u001b[0m Trial 182 finished with value: 0.932312925170068 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.12053235444193881, 'lr': 0.09922716775616407, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:09,386]\u001b[0m Trial 183 finished with value: 0.9363945578231293 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1582316724358661, 'lr': 0.09855700664895932, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-09 12:27:13,698]\u001b[0m Trial 184 finished with value: 0.9307823129251701 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.198274397563479, 'lr': 0.0838417632474021, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:15,504]\u001b[0m Trial 185 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:19,693]\u001b[0m Trial 186 finished with value: 0.9273809523809524 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.1803569353809289, 'lr': 0.08053608343046846, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:23,939]\u001b[0m Trial 187 finished with value: 0.9297619047619048 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.12031011524116846, 'lr': 0.06028130471683252, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:26,547]\u001b[0m Trial 188 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:30,794]\u001b[0m Trial 189 finished with value: 0.9306122448979591 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.13968216211954854, 'lr': 0.09939240218964525, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:35,093]\u001b[0m Trial 190 finished with value: 0.9336734693877551 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.11955036090849366, 'lr': 0.09943173317249855, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:38,560]\u001b[0m Trial 191 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:42,858]\u001b[0m Trial 192 finished with value: 0.9333333333333333 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.16092912818643834, 'lr': 0.09931289321083234, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:47,142]\u001b[0m Trial 193 finished with value: 0.9318027210884354 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'dropout_l0': 0.16203890959305456, 'lr': 0.07255890074239063, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:51,376]\u001b[0m Trial 194 finished with value: 0.932312925170068 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'dropout_l0': 0.12118720701828214, 'lr': 0.09981815987636956, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:54,039]\u001b[0m Trial 195 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:55,112]\u001b[0m Trial 196 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:27:56,227]\u001b[0m Trial 197 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:28:00,669]\u001b[0m Trial 198 finished with value: 0.9304421768707483 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'dropout_l0': 0.13749111443011205, 'lr': 0.0996248956214387, 'batch_size': 100, 'n_epochs': 5, 'optimizer': 'SGD'}. Best is trial 144 with value: 0.938265306122449.\u001b[0m\n",
      "\u001b[32m[I 2023-01-09 12:28:02,578]\u001b[0m Trial 199 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# instantiate optuna study\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "# run study\n",
    "study.optimize(objective, n_trials=200)  #, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62cfcc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  200\n",
      "  Number of pruned trials:  69\n",
      "  Number of complete trials:  131\n",
      "\n",
      "Best trial:\n",
      "  Validation Accuracy:  0.938265306122449\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 20\n",
      "    dropout_l0: 0.1304193070818448\n",
      "    lr: 0.08749252019850264\n",
      "    batch_size: 100\n",
      "    n_epochs: 5\n",
      "    optimizer: SGD\n"
     ]
    }
   ],
   "source": [
    "# Display study results\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"  Validation Accuracy: \", best_trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138155f",
   "metadata": {},
   "source": [
    "**Train final model using hyperparameters from best trial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83ec8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataloader(df, my_batchsize, my_shuffle, blind_test = False):\n",
    "    \"\"\"\n",
    "    Function to format dataframe as dataloader\n",
    "    :param df: dataframe\n",
    "    :param my_batchsize: batch size for dataloader\n",
    "    :param my_shuffle: whether to shuffle data at each epoch (True during training)\n",
    "    :param blind_test: True if df has no labels\n",
    "    :return: dataloader\n",
    "    \"\"\"\n",
    "    data = MyDataset(df, 'label', blind_test)\n",
    "    my_dataloader = DataLoader(data, batch_size=my_batchsize, shuffle=my_shuffle)\n",
    "\n",
    "    return my_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8b83a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(my_params):\n",
    "    \"\"\"\n",
    "    Train final model using tuned hyperparameters from best Optuna trial\n",
    "    :param my_params: dictionary of parameters from Optuna trial object that had best validation accuracy\n",
    "\n",
    "    :return: pytorch neural network model\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate model\n",
    "    model = define_model(my_params)\n",
    "\n",
    "    # Instantiate optimizer\n",
    "    optimizer_name = my_params['optimizer']\n",
    "    lr = my_params['lr']\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # get data. Entire training dataset is used here, including validation set\n",
    "    train_dataloader = df_to_dataloader(training_df, my_batchsize=my_params['batch_size'],\n",
    "                                                  my_shuffle=True)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(my_params['n_epochs']):\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # X and y are tensors. X.size() = (batch_size,n_features), y.size()=(batch_size,)\n",
    "            # set datatype for compatibility with nn.\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "\n",
    "            # calculate model output and resulting loss\n",
    "            model_output = model(X)  # tensor. size=(batch_size x n_classes)\n",
    "            loss_fn = nn.CrossEntropyLoss()  # instantiate loss function\n",
    "            loss = loss_fn(model_output, y)\n",
    "\n",
    "            # Backpropagation to update model weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7c6b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_trial.params  # extract optimised hyperparameters\n",
    "final_model = train_final_model(best_params)  # train final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844f081",
   "metadata": {},
   "source": [
    "**Evaluate final trianing accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab6b905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(model, df):\n",
    "    \"\"\"\n",
    "    Function to run trained and tuned model on provided dataframe to obtain predictions and evaluate\n",
    "    accuracy\n",
    "\n",
    "    :param model: trained model\n",
    "    :param df: dataframe including features and target/label\n",
    "\n",
    "    :return: accuracy\n",
    "    \"\"\"\n",
    "    my_dataloader = df_to_dataloader(df, my_batchsize=10, my_shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(my_dataloader):\n",
    "            X = X.float()\n",
    "            y = y.long()\n",
    "\n",
    "            # calculate model output and total number of correct predictions for this batch\n",
    "            model_output = model(X)\n",
    "            pred = torch.argmax(model_output, dim=1)  # prediction = class with highest output value\n",
    "            correct += count_correct(pred, y)\n",
    "\n",
    "    accuracy = correct / len(my_dataloader.dataset)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3caa2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final Training Accuracy: 0.9522789115646259\n"
     ]
    }
   ],
   "source": [
    "train_acc = predict_and_evaluate(final_model, training_df)\n",
    "print(f\"  Final Training Accuracy: {train_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd807b7",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Mock-Test\n",
    "Evaluate accuracy on mock-test data - i.e. portion of training data which was reserved at the start, and **not** used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd7639d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mock-test Accuracy: 0.9338095238095238\n"
     ]
    }
   ],
   "source": [
    "test_acc = predict_and_evaluate(final_model, mytest_df)\n",
    "print(f\"  Mock-test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0348fe",
   "metadata": {},
   "source": [
    "## <font color = 'blue'> Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "**STOP!! DO NOT OVERWRITE FILE!**\n",
    "fp = r\"Feed Forward Neural Network\\ffnn_2.pth\"\n",
    "torch.save(final_model, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df1a4ea",
   "metadata": {},
   "source": [
    "## <font color = 'orange'> Test\n",
    "Evaluate accuracy on kaggle test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff373bba",
   "metadata": {},
   "source": [
    "**Import Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e1ef225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel12  pixel13  pixel14  pixel15  pixel32  pixel33  pixel34  pixel35  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   pixel36  pixel37  ...  pixel770  pixel771  pixel772  pixel773  pixel774  \\\n",
       "0        0        0  ...         0         0         0         0         0   \n",
       "1        0        0  ...         0         0         0         0         0   \n",
       "2        0        0  ...         0         0         0         0         0   \n",
       "3        0        0  ...         0         0         0         0         0   \n",
       "4        0        0  ...         0         0         0         0         0   \n",
       "\n",
       "   pixel775  pixel776  pixel777  pixel778  pixel779  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 708 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = r\"test_filtered.csv\"\n",
    "test_df = pd.read_csv(fp)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11dc0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataloader\n",
    "test_dataloader = df_to_dataloader(test_df, my_batchsize=100, my_shuffle=False, blind_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47200b29",
   "metadata": {},
   "source": [
    "**Import & Run trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2410ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained model\n",
    "fp = r\"Feed Forward Neural Network\\ffnn_2.pth\"\n",
    "model = torch.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c4b3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch, X in enumerate(test_dataloader):\n",
    "        X = X.float()\n",
    "        model_output = model(X)\n",
    "        pred = torch.argmax(model_output, dim=1).numpy()  # prediction = class with highest output value\n",
    "        if batch==0:\n",
    "            predictions = pred\n",
    "        else:\n",
    "            predictions = np.append(predictions, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3413c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format in kaggle's required format\n",
    "image_id = np.arange(1,len(predictions)+1)\n",
    "predictions_df = pd.DataFrame.from_dict(data={'ImageId': image_id, 'Label': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "**STOP!! DO NOT OVERWRITE FILE!**\n",
    "fp = r\"Feed Forward Neural Network\\my_submission_ffnn2.csv\"\n",
    "predictions_df.to_csv(fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706c886",
   "metadata": {},
   "source": [
    "**<font color = 'orange'> Test Results (from Kaggle)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e33455d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ffnn_1</td>\n",
       "      <td>0.82300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ffnn_2</td>\n",
       "      <td>0.84639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  accuracy\n",
       "0  ffnn_1   0.82300\n",
       "1  ffnn_2   0.84639"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_results = {'ffnn_1':0.823,\n",
    "             'ffnn_2': 0.84639}\n",
    "\n",
    "myresults_df = pd.DataFrame.from_dict(my_results, 'index').reset_index().rename({'index':'model',0:'accuracy'},axis=1)\n",
    "myresults_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767374a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
